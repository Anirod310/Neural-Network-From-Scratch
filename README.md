# Neural-network-from-scratch
A project in which I learn to code a L-layer neural network from scratch, using numpy and matplotlib. The project is separated in different stages : 
- Build a simple L-layer neural network with simple hyperparameter and gradient descent implementations :
    - Try different parameter initialisations.
    - Try different activation functions.
    - Vary the size of the neural network (adding/removing layers/nodes).
    - Analyze the results for each case.

- Improve the model by adding regularization :
    - Try L2 regularization and Dropout and analyze the results for each.

- Improve the model even more by implementing better optimizers methods :
    - Implement momentum
    - Implement Adam


You can follow the entire project walkthrough in the [report](REPORT.md) file.
## Environment

To ensure reproducibility, the following environment setup is recommended:

- **Python version**: 3.8 or later
- **IDE**: Jupyter Notebook or any other Python IDE
## Dependencies

Install the required dependencies using the following command:

```bash
pip install -r requirements.txt
```
## Troubleshooting  

If you are having trouble getting the model to work, you can check the following :
- Make sure that you installed the correct dependencies.
- Make sure that the data are formated correctly.
If you still have trouble, you can ask for help on a forum or chat room dedicated to linear regression, or contact me at **bousek.dorian@gmail.com**.  

I hope this helps ! 
